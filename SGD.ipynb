{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZgmVqhsWR3qsAa2JI0evC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasannashrestha011/ML_exercises/blob/main/SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ycO64_xT8pVh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# y = 2x + 3 + noise\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 1)   # 100 samples\n",
        "y = 2 * X + 3 + 0.1 * np.random.randn(100, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w=np.random.randn(1)\n",
        "b=np.random.randn(1)"
      ],
      "metadata": {
        "id": "3XTsetCy8_Mk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(w,X,b):\n",
        "  return w*X+b\n",
        "def mse_loss(y_true,y_pred):\n",
        "  return np.mean((y_true-y_pred)**2)"
      ],
      "metadata": {
        "id": "JN1C84fZ9Fnt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_update(X_batch,y_batch,w,b,lr=0.01):\n",
        "   y_pred=predict(w,X_batch,b)\n",
        "   dw=-2*np.mean(X_batch * (y_batch-y_pred),axis=0)\n",
        "   db=-2*np.mean(y_batch-y_pred)\n",
        "\n",
        "   w=w-lr*dw\n",
        "   b=b-lr*db\n",
        "   return w,b"
      ],
      "metadata": {
        "id": "ei2Dkwuc9b5N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=60\n",
        "batch_size=20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  indicies=np.arange(X.shape[0])\n",
        "  np.random.shuffle(indicies)\n",
        "\n",
        "  X=X[indicies]\n",
        "  y=y[indicies]\n",
        "\n",
        "  for i in range(0,len(X),batch_size):\n",
        "    X_batch=X[i:i+batch_size]\n",
        "    y_batch=y[i:i+batch_size]\n",
        "\n",
        "    w,b=sgd_update(X_batch,y_batch,w,b)\n",
        "\n",
        "  y_pred=predict(w,X,b)\n",
        "  loss=mse_loss(y,y_pred)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, w: {w[0]:.4f}, b: {b[0]:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BhrHJFD_c2_",
        "outputId": "c7ddd230-92c6-4fe2-816f-8ffe5acb2809"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.6136, w: 1.0498, b: 0.2787\n",
            "Epoch 2, Loss: 6.3036, w: 1.0984, b: 0.5312\n",
            "Epoch 3, Loss: 5.2233, w: 1.1457, b: 0.7598\n",
            "Epoch 4, Loss: 4.3314, w: 1.1910, b: 0.9671\n",
            "Epoch 5, Loss: 3.5945, w: 1.2351, b: 1.1548\n",
            "Epoch 6, Loss: 2.9858, w: 1.2774, b: 1.3249\n",
            "Epoch 7, Loss: 2.4823, w: 1.3179, b: 1.4790\n",
            "Epoch 8, Loss: 2.0656, w: 1.3567, b: 1.6187\n",
            "Epoch 9, Loss: 1.7201, w: 1.3937, b: 1.7455\n",
            "Epoch 10, Loss: 1.4339, w: 1.4290, b: 1.8603\n",
            "Epoch 11, Loss: 1.1963, w: 1.4625, b: 1.9646\n",
            "Epoch 12, Loss: 0.9992, w: 1.4945, b: 2.0590\n",
            "Epoch 13, Loss: 0.8354, w: 1.5248, b: 2.1448\n",
            "Epoch 14, Loss: 0.6992, w: 1.5534, b: 2.2225\n",
            "Epoch 15, Loss: 0.5859, w: 1.5805, b: 2.2931\n",
            "Epoch 16, Loss: 0.4915, w: 1.6061, b: 2.3571\n",
            "Epoch 17, Loss: 0.4129, w: 1.6303, b: 2.4153\n",
            "Epoch 18, Loss: 0.3473, w: 1.6531, b: 2.4680\n",
            "Epoch 19, Loss: 0.2926, w: 1.6747, b: 2.5159\n",
            "Epoch 20, Loss: 0.2468, w: 1.6949, b: 2.5595\n",
            "Epoch 21, Loss: 0.2086, w: 1.7140, b: 2.5990\n",
            "Epoch 22, Loss: 0.1766, w: 1.7319, b: 2.6350\n",
            "Epoch 23, Loss: 0.1498, w: 1.7487, b: 2.6677\n",
            "Epoch 24, Loss: 0.1274, w: 1.7644, b: 2.6974\n",
            "Epoch 25, Loss: 0.1086, w: 1.7792, b: 2.7244\n",
            "Epoch 26, Loss: 0.0929, w: 1.7931, b: 2.7490\n",
            "Epoch 27, Loss: 0.0796, w: 1.8060, b: 2.7713\n",
            "Epoch 28, Loss: 0.0685, w: 1.8182, b: 2.7916\n",
            "Epoch 29, Loss: 0.0592, w: 1.8296, b: 2.8101\n",
            "Epoch 30, Loss: 0.0513, w: 1.8403, b: 2.8268\n",
            "Epoch 31, Loss: 0.0447, w: 1.8503, b: 2.8421\n",
            "Epoch 32, Loss: 0.0391, w: 1.8596, b: 2.8561\n",
            "Epoch 33, Loss: 0.0344, w: 1.8683, b: 2.8688\n",
            "Epoch 34, Loss: 0.0305, w: 1.8764, b: 2.8803\n",
            "Epoch 35, Loss: 0.0271, w: 1.8840, b: 2.8908\n",
            "Epoch 36, Loss: 0.0243, w: 1.8910, b: 2.9004\n",
            "Epoch 37, Loss: 0.0220, w: 1.8976, b: 2.9092\n",
            "Epoch 38, Loss: 0.0200, w: 1.9038, b: 2.9171\n",
            "Epoch 39, Loss: 0.0183, w: 1.9095, b: 2.9243\n",
            "Epoch 40, Loss: 0.0168, w: 1.9148, b: 2.9310\n",
            "Epoch 41, Loss: 0.0156, w: 1.9198, b: 2.9370\n",
            "Epoch 42, Loss: 0.0146, w: 1.9245, b: 2.9425\n",
            "Epoch 43, Loss: 0.0137, w: 1.9288, b: 2.9475\n",
            "Epoch 44, Loss: 0.0130, w: 1.9329, b: 2.9520\n",
            "Epoch 45, Loss: 0.0124, w: 1.9366, b: 2.9562\n",
            "Epoch 46, Loss: 0.0118, w: 1.9401, b: 2.9600\n",
            "Epoch 47, Loss: 0.0114, w: 1.9434, b: 2.9635\n",
            "Epoch 48, Loss: 0.0110, w: 1.9464, b: 2.9667\n",
            "Epoch 49, Loss: 0.0107, w: 1.9492, b: 2.9696\n",
            "Epoch 50, Loss: 0.0104, w: 1.9518, b: 2.9722\n",
            "Epoch 51, Loss: 0.0102, w: 1.9542, b: 2.9746\n",
            "Epoch 52, Loss: 0.0100, w: 1.9564, b: 2.9769\n",
            "Epoch 53, Loss: 0.0098, w: 1.9586, b: 2.9789\n",
            "Epoch 54, Loss: 0.0097, w: 1.9605, b: 2.9807\n",
            "Epoch 55, Loss: 0.0095, w: 1.9624, b: 2.9824\n",
            "Epoch 56, Loss: 0.0094, w: 1.9641, b: 2.9839\n",
            "Epoch 57, Loss: 0.0093, w: 1.9657, b: 2.9853\n",
            "Epoch 58, Loss: 0.0093, w: 1.9671, b: 2.9866\n",
            "Epoch 59, Loss: 0.0092, w: 1.9685, b: 2.9878\n",
            "Epoch 60, Loss: 0.0091, w: 1.9697, b: 2.9889\n"
          ]
        }
      ]
    }
  ]
}